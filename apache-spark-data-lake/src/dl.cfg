[AWS]
name = aws_admin
aws_access_key_id = <ENTER AWS ACCESS KEY>
aws_secret_access_key = <ENTER AWS SECRET KEY>
region_name = <ENTER AWS REGION NAME>

[S3]
output_bucket = udacity-spark-data-lake
script_name = etl.py
source_bucket = udacity-spark-etl

[DATALAKE]
input_data = s3a://udacity-dend/
output_data = s3a://udacity-spark-data-lake/

[EMR]
name = spark-emr-cluster
log_uri = s3://udacity-spark-data-lake-logs-us-west-2
job_flow_role = EMR_EC2_DefaultRole
service_role = MyEmrRole
policy_arn_1 = arn:aws:iam::aws:policy/AmazonS3FullAccess
policy_arn_2 = arn:aws:iam::aws:policy/service-role/AmazonElasticMapReduceRole

